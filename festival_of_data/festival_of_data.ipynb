{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arup Festival of Data\n",
    "\n",
    "## Welcome\n",
    "\n",
    "Here you will find code used to build synthetic city data for the Arup Festival of Data challenge.\n",
    "\n",
    "## What is City Chef?\n",
    "\n",
    "We've been researching and building new approaches to modelling human behaviour in cities and countries. With the aim of helping design better and farer policies and infrastructure for the future. A hugely important consideration of our work is the complexity and hetrogeneity of humans. No one is the same and no one should be treated the same when trying to plan the future.\n",
    "\n",
    "But this often puts us in an awkward possition for our research - data about people and their behaiour is useful to us, but accessing it is hard, the quality is often dubious and we prefer not to work with sensitive personal data.\n",
    "\n",
    "City Chef is our tool for working around this data challenge. City Chef builds fake data for use by researchers and modellers looking to develop and test new approaches. City Chef has some key aims:\n",
    "\n",
    "1. Output data that is often not obsevred or measured\n",
    "2. Output data in useful formats\n",
    "3. Use representative physical components, such as networks\n",
    "4. Use representative probabilistic components, such as age distributions\n",
    "\n",
    "and where (4) fails: (5) Use representative complexity in the distributions\n",
    "\n",
    "## Outputs\n",
    "\n",
    "Our focus is often to produce human level data, such as **household census**, **commuter surveys** and **household travel surveys**. But we also create the following city data:\n",
    "\n",
    "**Facilities:** activity locations (including households)\n",
    "\n",
    "**Road Networks:**\n",
    "\n",
    "**Road Transit Routes:** Car routes using the road network\n",
    "\n",
    "**Rail Transit Network and Routes:**\n",
    "\n",
    "**Statistical Zones:**\n",
    "\n",
    "**Population:** Generate a population of agents, with consistent household attributes. The distribution of the population attributes is dependant on the above spatial features and some encoded underlying distributions.\n",
    "\n",
    "**Plans:** Generate simple activity based plans for each agent, currently only supports simple tour based plans. The distribution of the plan attributes, such as activity choice and mode, is dependant on the agent, facility and network features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T21:28:56.193915Z",
     "start_time": "2021-09-09T21:28:55.248063Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'citychef'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-3143777c849a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcitychef\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mspatial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcitychef\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcitychef\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mhousehold\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'citychef'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import Point\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import networkx as nx\n",
    "from scipy.spatial.distance import cdist\n",
    "import os\n",
    "\n",
    "from citychef import spatial\n",
    "from citychef import graph\n",
    "from citychef import household as hh\n",
    "from citychef import person\n",
    "from citychef import tree\n",
    "from citychef import choice\n",
    "from citychef import osm, gtfs\n",
    "from citychef.household import minmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T21:27:41.304717Z",
     "start_time": "2021-09-09T21:27:08.417Z"
    }
   },
   "outputs": [],
   "source": [
    "city_dir = \"./city_A\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T21:27:41.307425Z",
     "start_time": "2021-09-09T21:27:08.422Z"
    }
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(city_dir):\n",
    "    os.mkdir(city_dir)\n",
    "else:\n",
    "    print(\"WARNING - potentially overwritting previous results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T21:27:41.310727Z",
     "start_time": "2021-09-09T21:27:08.425Z"
    }
   },
   "outputs": [],
   "source": [
    "# city A\n",
    "TARGET_HHS = 2000\n",
    "SEED_AREA = [[275000,780000],[277000,782000]]\n",
    "TARGET_CENTRES = 5\n",
    "BUS_ROUTES = 12\n",
    "TRAIN_ROUTES = 4\n",
    "\n",
    "# city B\n",
    "# TARGET_HHS = 2000\n",
    "# SEED_AREA = [[275000,780000],[277000,782000]]\n",
    "# TARGET_CENTRES = 4\n",
    "# BUS_ROUTES = 12\n",
    "# TRAIN_ROUTES = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T21:27:41.315918Z",
     "start_time": "2021-09-09T21:27:08.428Z"
    }
   },
   "outputs": [],
   "source": [
    "(x0, y0), (x1, y1) = SEED_AREA\n",
    "area = (x1-x0) * (y1-y0)\n",
    "centres = spatial.Centres(SEED_AREA, density = TARGET_CENTRES/area)\n",
    "\n",
    "spread = ((x1-x0) + (y1-y1))/10\n",
    "facilities = {\n",
    "    'households': spatial.Clusters(centres, size=TARGET_HHS, sigma=spread).crop_to_bbox(SEED_AREA),\n",
    "    'work': spatial.Clusters(centres, size=TARGET_HHS/10, sigma=spread/2).crop_to_bbox(SEED_AREA),\n",
    "    'leisure': spatial.Clusters(centres, size=TARGET_HHS/20, sigma=spread/2).crop_to_bbox(SEED_AREA),\n",
    "    'education': spatial.Clusters(centres, size=TARGET_HHS/20, sigma=spread/3).crop_to_bbox(SEED_AREA),\n",
    "    'health': spatial.Clusters(centres, size=TARGET_HHS/50, sigma=spread/3).crop_to_bbox(SEED_AREA),\n",
    "    'shopping': spatial.Clusters(centres, size=TARGET_HHS/20, sigma=spread/4).crop_to_bbox(SEED_AREA),\n",
    "}\n",
    "bbox = spatial.collect_bbox(facilities) # adjust the bbox for max extends\n",
    "\n",
    "spatial.write_buildings_geojson(\n",
    "    facilities,\n",
    "    path=os.path.join(city_dir, \"building_locations.geojson\"),\n",
    "    epsg=\"epsg:27700\",\n",
    "    to_epsg=\"epsg:4326\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T21:27:41.318755Z",
     "start_time": "2021-09-09T21:27:08.432Z"
    }
   },
   "outputs": [],
   "source": [
    "car_network = graph.TreeNetwork(bbox, facilities['households'], grid='regular', max_points=50, label=\"highway\")\n",
    "\n",
    "# osm.nx_to_osm(\n",
    "#     g=car_network.g,\n",
    "#     path=os.path.join(city_dir, \"car_osm.xml\")\n",
    "# )\n",
    "graph.nx_to_geojson(\n",
    "    g=car_network.g,\n",
    "    path=os.path.join(city_dir, \"car_network.geojson\"),\n",
    "    epsg=\"epsg:27700\",\n",
    "    to_epsg=\"epsg:4326\"\n",
    ")\n",
    "# fig.savefig(os.path.join(city_dir, 'road_network.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T21:27:41.321947Z",
     "start_time": "2021-09-09T21:27:08.436Z"
    }
   },
   "outputs": [],
   "source": [
    "buses = graph.Transit(car_network, facilities['households'], density_radius=1000)\n",
    "bus_routes = buses.build_routes(num_routes=BUS_ROUTES, max_length=30, min_length=10, straightness=2)\n",
    "total_bus_graph = buses.graph\n",
    "\n",
    "gtfs.build_gtfs(\n",
    "    transit=buses,\n",
    "    name=\"bus\",\n",
    "    out_dir=city_dir,\n",
    "    agency_id=0,\n",
    "    agency_name='bus_connect',\n",
    "    frequency=10,\n",
    "    from_epsg=\"epsg:27700\",\n",
    "    to_epsg=\"epsg:4326\"\n",
    ")\n",
    "\n",
    "graph.nx_to_geojson(\n",
    "    g=buses.graph,\n",
    "    path=os.path.join(city_dir, \"bus_network.geojson\"),\n",
    "    epsg=\"epsg:27700\",\n",
    "    to_epsg=\"epsg:4326\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T21:27:41.324698Z",
     "start_time": "2021-09-09T21:27:08.439Z"
    }
   },
   "outputs": [],
   "source": [
    "potential_stations = np.array([v['pos'] for k, v in car_network.g.nodes.items() if k[:2] == '00'])\n",
    "rail_network = graph.DelaunayNetwork(potential_stations)\n",
    "\n",
    "trains = graph.Transit(rail_network, facilities['households'])\n",
    "train_routes = trains.build_routes(num_routes=TRAIN_ROUTES, max_length=12, min_length=10, straightness=20)\n",
    "\n",
    "total_train_graph = trains.graph\n",
    "\n",
    "gtfs.build_gtfs(\n",
    "    transit=trains,\n",
    "    name=\"rail\",\n",
    "    out_dir=city_dir,\n",
    "    agency_id=1,\n",
    "    agency_name='rail_get_you_there',\n",
    "    frequency=30,\n",
    "    from_epsg=\"epsg:27700\",\n",
    "    to_epsg=\"epsg:4326\"\n",
    ")\n",
    "\n",
    "graph.nx_to_geojson(\n",
    "    g=trains.graph,\n",
    "    path=os.path.join(city_dir, \"rail_network.geojson\"),\n",
    "    epsg=\"epsg:27700\",\n",
    "    to_epsg=\"epsg:4326\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T21:27:41.329999Z",
     "start_time": "2021-09-09T21:27:08.441Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(12, 12))\n",
    "spatial.plot_facilities(facilities, centres=centres, ax=ax)\n",
    "car_network.plot(ax=ax)\n",
    "buses.plot(ax=ax)\n",
    "trains.plot(ax=ax, line_colour='blue')\n",
    "fig.patch.set_visible(False)\n",
    "# ax.axis('off')\n",
    "# plt.axis('equal')\n",
    "\n",
    "# fig.savefig(os.path.join(city_dir, 'city.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T21:27:41.332660Z",
     "start_time": "2021-09-09T21:27:08.444Z"
    }
   },
   "outputs": [],
   "source": [
    "hh_df = pd.DataFrame(range(facilities['households'].size), columns=['hh_index'])\n",
    "hh_hidden_df = pd.DataFrame(range(facilities['households'].size), columns=['hh_index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T21:27:41.335305Z",
     "start_time": "2021-09-09T21:27:08.448Z"
    }
   },
   "outputs": [],
   "source": [
    "zones = tree.Zones(\n",
    "    bbox=bbox, \n",
    "    facilities=facilities['households'],\n",
    "    max_zone_facilities=400,\n",
    "    max_sub_zone_facilities=100,\n",
    ")\n",
    "zones.plot()\n",
    "\n",
    "zones.zone_gdf.crs = \"EPSG:27700\"\n",
    "zones.zone_gdf.to_crs(\"epsg:4226\").to_file(os.path.join(city_dir, \"administrative_areas.geojson\"), driver='GeoJSON')\n",
    "\n",
    "zones.sub_zone_gdf.crs = \"EPSG:27700\"\n",
    "zones.sub_zone_gdf.to_crs(\"epsg:4226\").to_file(os.path.join(city_dir, \"administrative_zones.geojson\"), driver='GeoJSON')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T21:27:41.339153Z",
     "start_time": "2021-09-09T21:27:08.451Z"
    }
   },
   "outputs": [],
   "source": [
    "# fig.savefig(os.path.join(city_dir, 'density.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T21:27:41.342146Z",
     "start_time": "2021-09-09T21:27:08.453Z"
    }
   },
   "outputs": [],
   "source": [
    "hhs = facilities['households']\n",
    "work = facilities['work']\n",
    "leisure = facilities['leisure']\n",
    "education = facilities['education']\n",
    "health = facilities['health']\n",
    "shopping = facilities['shopping']\n",
    "\n",
    "hh_dist_to_centre = hhs.dist_to_centres()\n",
    "hh_dist_to_centre_mm = minmax(hh_dist_to_centre)\n",
    "\n",
    "hh_df['area_id'] = zones.facility_zone_ids\n",
    "hh_df['zone_id'] = zones.facility_sub_zone_ids\n",
    "\n",
    "n = centres.size\n",
    "\n",
    "hh_hidden_df['density_mm'] = spatial.density(hhs, hhs)\n",
    "hh_hidden_df['dist_closest_centre_mm'] = spatial.distances_to_closest(hhs, centres, 1)\n",
    "hh_hidden_df['dist_closest_centres_mm'] = spatial.distances_to_closest(hhs, centres, max([n,3]))\n",
    "hh_hidden_df['density_work_places_mm'] = spatial.density(hhs, work, 500)\n",
    "hh_hidden_df['density_leisure_mm'] = spatial.density(hhs, leisure, 500)\n",
    "hh_hidden_df['dist_closest_schools_mm'] = spatial.distances_to_closest(hhs, education, max([n,2]))\n",
    "hh_hidden_df['dist_closest_health_mm'] = spatial.density(hhs, health, 500)\n",
    "\n",
    "hh_locs_mm = minmax(hhs.locs)\n",
    "hh_centre_ids_mm = minmax(hhs.ids)\n",
    "\n",
    "hh_hidden_df['hidden'] = hh.gen_hidden(hh_locs_mm[:,0], hh_locs_mm[:,1], hh_hidden_df['density_mm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T21:27:41.346721Z",
     "start_time": "2021-09-09T21:27:08.456Z"
    }
   },
   "outputs": [],
   "source": [
    "hh_hidden_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T12:25:02.854695Z",
     "start_time": "2019-12-02T12:25:02.830443Z"
    }
   },
   "source": [
    "### Household Features\n",
    "\n",
    "Household features are generated based on hidden features and previously generated features. All generative funtions combine some level of probabalitic sampling. Data sampling is designed to generate non linear and complex dependancies. The aim of which is to create a population with complex and noisy interdependencies between features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T21:27:41.349250Z",
     "start_time": "2021-09-09T21:27:08.460Z"
    }
   },
   "outputs": [],
   "source": [
    "hh_df['hh_count'] = hh.gen_hh_count(\n",
    "    hh_hidden_df['hidden'], \n",
    "    hh_hidden_df['density_mm']\n",
    ")\n",
    "\n",
    "hh_df['hh_children'] = hh.gen_num_children(\n",
    "    hh_df['hh_count'],\n",
    "    hh_hidden_df['hidden'],\n",
    "    hh_hidden_df['dist_closest_schools_mm'],\n",
    "    hh_hidden_df['density_leisure_mm']\n",
    ")\n",
    "\n",
    "hh_hidden_df['age_group'] = hh.gen_age_group(\n",
    "    hh_df['hh_children'],\n",
    "    hh_hidden_df['hidden'],\n",
    "    hh_hidden_df['density_mm']\n",
    ")\n",
    "\n",
    "hh_df['hh_people_in_work'] = hh.get_people_in_work(\n",
    "    hh_hidden_df['age_group'],\n",
    "    hh_hidden_df['hidden'],\n",
    "    hh_df['hh_count'],\n",
    "    hh_df['hh_children'],\n",
    "    hh_hidden_df['density_mm']\n",
    ")\n",
    "\n",
    "hh_df['hh_in_work'] = hh.get_in_work(\n",
    "    hh_df['hh_people_in_work']\n",
    ")\n",
    "\n",
    "hh_df['hh_income'] = hh.get_income(\n",
    "    hh_df['hh_in_work'],\n",
    "    hh_df['hh_count'],\n",
    "    hh_df['hh_children'],\n",
    "    hh_hidden_df['density_work_places_mm'],\n",
    "    hh_hidden_df['density_mm']\n",
    ")\n",
    "\n",
    "hh_income_mm = minmax(hh_df['hh_income'])\n",
    "\n",
    "hh_df['hh_cars'] = hh.get_cars(\n",
    "    hh_hidden_df['hidden'],\n",
    "    hh_income_mm,\n",
    "    hh_hidden_df['density_mm'],\n",
    "    hh_df['hh_count'],\n",
    "    hh_df['hh_children']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T21:27:41.353135Z",
     "start_time": "2021-09-09T21:27:08.464Z"
    }
   },
   "outputs": [],
   "source": [
    "hh_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T12:25:06.564761Z",
     "start_time": "2019-12-02T12:25:02.981482Z"
    }
   },
   "source": [
    "### Individual Features\n",
    "\n",
    "Individuals features are generated based on their household hidden features and previously generated features. As per for households, all generative funtions combine some level of probabalitic sampling. Data sampling is designed to generate non linear and complex dependancies. The aim of which is to create a population with complex and noisy interdependencies between features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T21:27:41.357563Z",
     "start_time": "2021-09-09T21:27:08.466Z"
    }
   },
   "outputs": [],
   "source": [
    "# hh features\n",
    "hh_counts = hh_df['hh_count'].to_numpy()\n",
    "agent_hh_array = np.repeat(hh_df.to_numpy(), hh_counts, axis=0)\n",
    "person_df = pd.DataFrame(agent_hh_array)\n",
    "person_df.columns = hh_df.columns\n",
    "person_df['p_hh_index'] = np.array([i for c in hh_df['hh_count'] for i in range(c)])\n",
    "\n",
    "#hidden vectors\n",
    "agent_hidden_array = np.repeat(hh_hidden_df.to_numpy(), hh_counts, axis=0)\n",
    "person_hidden_df = pd.DataFrame(agent_hidden_array)\n",
    "person_hidden_df.columns = hh_hidden_df.columns\n",
    "person_hidden_df['p_hh_index'] = np.array([i for c in hh_df['hh_count'] for i in range(c)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T21:27:41.360771Z",
     "start_time": "2021-09-09T21:27:08.468Z"
    }
   },
   "outputs": [],
   "source": [
    "person_df['adult'] = person.get_is_adult(\n",
    "    person_df['p_hh_index'],\n",
    "    person_df['hh_count'],\n",
    "    person_df['hh_children']\n",
    ")\n",
    "\n",
    "person_df['gender'] = person.get_gender(\n",
    "    person_df['p_hh_index'], \n",
    "    person_df['adult'],\n",
    "    person_df['hh_children'],\n",
    "    person_hidden_df['hidden']\n",
    ")\n",
    "\n",
    "person_df['age'] = person.get_age(\n",
    "    person_hidden_df['hidden'],\n",
    "    person_hidden_df['age_group'],\n",
    "    person_df['adult']\n",
    ")\n",
    "\n",
    "person_df['employment'] = person.employment(\n",
    "    person_df['adult'],\n",
    "    person_df['hh_people_in_work'],\n",
    "    person_df['p_hh_index'],\n",
    "    person_df['age'],\n",
    "    person_hidden_df['hidden'],\n",
    "    person_hidden_df['dist_closest_schools_mm'],\n",
    "    person_hidden_df['density_work_places_mm'],\n",
    "    person_df['hh_income'],\n",
    "    person_hidden_df['density_mm'],\n",
    ")\n",
    "\n",
    "person_df['occupation'] = person.occupation(\n",
    "    person_df['employment'],\n",
    "    person_df['age'],\n",
    "    minmax(person_df['hh_income']),\n",
    ")\n",
    "\n",
    "person_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T21:27:41.364888Z",
     "start_time": "2021-09-09T21:27:08.470Z"
    }
   },
   "outputs": [],
   "source": [
    "person_hidden_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T21:27:41.367639Z",
     "start_time": "2021-09-09T21:27:08.472Z"
    }
   },
   "outputs": [],
   "source": [
    "print(len(person_df))\n",
    "print(len(hh_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activity Choice\n",
    "\n",
    "A simple activity plan is generated based on individual features. This plan consists of a single activity at a given facility location.\n",
    "\n",
    "#### Method\n",
    "1. Activity type choice is made based on household and individual features. This can include staying at home.\n",
    "2. Facilities for each activity type are weighted by their desirability (based on density and distance).\n",
    "3. Agents randomly choose a facility based on this weighting and on their individual features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T21:27:41.375770Z",
     "start_time": "2021-09-09T21:27:08.474Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Main activity choice\n",
    "person_df['main_activity'] = choice.main_activity_choice(\n",
    "    person_df['employment'],\n",
    "    person_hidden_df['density_work_places_mm'],\n",
    "    person_df['occupation'],\n",
    "    person_hidden_df['hidden'],\n",
    "    minmax(person_df['hh_income']),\n",
    "    person_df['hh_count'],\n",
    "    person_hidden_df['dist_closest_centres_mm'],\n",
    "    person_hidden_df['density_leisure_mm'],\n",
    "    person_df['age'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T21:27:41.383013Z",
     "start_time": "2021-09-09T21:27:08.477Z"
    }
   },
   "outputs": [],
   "source": [
    "person_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T21:27:41.388967Z",
     "start_time": "2021-09-09T21:27:08.479Z"
    }
   },
   "outputs": [],
   "source": [
    "# FACILITY FEATURES\n",
    "zone_gdf = zones.sub_zone_gdf\n",
    "\n",
    "work_df = pd.DataFrame(range(work.size), columns=['index'])\n",
    "work_df['density_mm'] = spatial.density(work, work, 500)\n",
    "work_df['geometry'] = [Point(x,y) for x,y in work.locs]\n",
    "work_gdf = gpd.GeoDataFrame(work_df, geometry='geometry')\n",
    "work_gdf = gpd.sjoin(work_gdf, zone_gdf, how=\"left\", op='within').drop('index_right', axis=1)\n",
    "\n",
    "leisure_df = pd.DataFrame(range(leisure.size), columns=['index'])\n",
    "leisure_df['density_mm'] = spatial.density(leisure, shopping, 500)\n",
    "leisure_df['geometry'] = [Point(x,y) for x,y in leisure.locs]\n",
    "leisure_gdf = gpd.GeoDataFrame(leisure_df, geometry='geometry')\n",
    "leisure_gdf = gpd.sjoin(leisure_gdf, zone_gdf, how=\"left\", op='within').drop('index_right', axis=1)\n",
    "\n",
    "education_df = pd.DataFrame(range(education.size), columns=['index'])\n",
    "education_df['density_mm'] = spatial.density(education, shopping, 500)\n",
    "education_df['geometry'] = [Point(x,y) for x,y in education.locs]\n",
    "education_gdf = gpd.GeoDataFrame(education_df, geometry='geometry')\n",
    "education_gdf = gpd.sjoin(education_gdf, zone_gdf, how=\"left\", op='within').drop('index_right', axis=1)\n",
    "\n",
    "health_df = pd.DataFrame(range(health.size), columns=['index'])\n",
    "health_df['density_mm'] = spatial.density(health, shopping, 500)\n",
    "health_df['geometry'] = [Point(x,y) for x,y in health.locs]\n",
    "health_gdf = gpd.GeoDataFrame(health_df, geometry='geometry')\n",
    "health_gdf = gpd.sjoin(health_gdf, zone_gdf, how=\"left\", op='within').drop('index_right', axis=1)\n",
    "\n",
    "shopping_df = pd.DataFrame(range(shopping.size), columns=['index'])\n",
    "shopping_df['density_mm'] = spatial.density(shopping, shopping, 300)\n",
    "shopping_df['geometry'] = [Point(x,y) for x,y in shopping.locs]\n",
    "shopping_gdf = gpd.GeoDataFrame(shopping_df, geometry='geometry')\n",
    "shopping_gdf = gpd.sjoin(shopping_gdf, zone_gdf, how=\"left\", op='within').drop('index_right', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T21:27:41.393475Z",
     "start_time": "2021-09-09T21:27:08.481Z"
    }
   },
   "outputs": [],
   "source": [
    "hhs_work_distances = minmax(cdist(hhs.locs, work.locs))\n",
    "hhs_education_distances = minmax(cdist(hhs.locs, education.locs))\n",
    "hhs_shopping_distances = minmax(cdist(hhs.locs, shopping.locs))\n",
    "hhs_leisure_distances = minmax(cdist(hhs.locs, leisure.locs))\n",
    "hhs_health_distances = minmax(cdist(hhs.locs, health.locs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T21:27:41.401993Z",
     "start_time": "2021-09-09T21:27:08.482Z"
    }
   },
   "outputs": [],
   "source": [
    "main_facility_id = np.zeros((len(person_df)))\n",
    "main_facility_area = np.zeros((len(person_df)))\n",
    "main_facility_zone = np.zeros((len(person_df)))\n",
    "\n",
    "for i, (hh_index, main_act, income_mm) in enumerate(zip(person_df.hh_index, person_df.main_activity, minmax(person_df['hh_income']))):\n",
    "    \n",
    "    if main_act == 0:  # home\n",
    "        main_facility_id[i] = -1\n",
    "        main_facility_area[i] = -1\n",
    "        main_facility_zone[i] = -1\n",
    "        \n",
    "    hh_index = int(hh_index)\n",
    "        \n",
    "    if main_act == 1:  # work\n",
    "        facility_distances = hhs_work_distances[hh_index]\n",
    "        facility_scores = (1 - income_mm) * (1 - facility_distances) + income_mm * work_df.density_mm\n",
    "        facility_scores = facility_scores / facility_scores.sum()\n",
    "        facitlity_id = np.random.choice(range(len(facility_scores)), p=facility_scores)\n",
    "        main_facility_id[i] = facitlity_id\n",
    "        main_facility_area[i], main_facility_zone[i] = work_gdf[['area_id', 'zone_id']].iloc[facitlity_id]\n",
    "        continue\n",
    "        \n",
    "    if main_act == 2:  # education\n",
    "        facility_distances = hhs_education_distances[hh_index]\n",
    "        facility_scores = (1 - facility_distances) ** 2\n",
    "        facility_scores = facility_scores / facility_scores.sum()\n",
    "        facitlity_id = np.random.choice(range(len(facility_scores)), p=facility_scores)\n",
    "        main_facility_id[i] = facitlity_id\n",
    "        main_facility_area[i], main_facility_zone[i] = education_gdf[['area_id', 'zone_id']].iloc[facitlity_id]\n",
    "        continue\n",
    "        \n",
    "    if main_act == 3:  # shopping\n",
    "        facility_distances = hhs_shopping_distances[hh_index]\n",
    "        facility_scores = (1 - income_mm) * (1 - facility_distances) + income_mm * shopping_df.density_mm\n",
    "        facility_scores = facility_scores / facility_scores.sum()\n",
    "        facitlity_id = np.random.choice(range(len(facility_scores)), p=facility_scores)\n",
    "        main_facility_id[i] = facitlity_id\n",
    "        main_facility_area[i], main_facility_zone[i] = shopping_gdf[['area_id', 'zone_id']].iloc[facitlity_id]\n",
    "        continue\n",
    "        \n",
    "    if main_act == 4:  # leisure\n",
    "        facility_distances = hhs_leisure_distances[hh_index]\n",
    "        facility_scores = (1 - facility_distances)\n",
    "        facility_scores = facility_scores / facility_scores.sum()\n",
    "        facitlity_id = np.random.choice(range(len(facility_scores)), p=facility_scores)\n",
    "        main_facility_id[i] = facitlity_id\n",
    "        main_facility_area[i], main_facility_zone[i] = leisure_gdf[['area_id', 'zone_id']].iloc[facitlity_id]\n",
    "        continue\n",
    "        \n",
    "    if main_act == 5:  # health\n",
    "        facility_distances = hhs_health_distances[hh_index]\n",
    "        facility_scores = (1 - facility_distances) ** 4\n",
    "        facility_scores = facility_scores / facility_scores.sum()\n",
    "        facitlity_id = np.random.choice(range(len(facility_scores)), p=facility_scores)\n",
    "        main_facility_id[i] = facitlity_id\n",
    "        main_facility_area[i], main_facility_zone[i] = health_gdf[['area_id', 'zone_id']].iloc[facitlity_id]\n",
    "        continue\n",
    "\n",
    "person_df['main_activity_id'] = main_facility_id\n",
    "person_df['main_facility_area'] = main_facility_area\n",
    "person_df['main_facility_zone'] = main_facility_zone\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T21:27:41.406098Z",
     "start_time": "2021-09-09T21:27:08.484Z"
    }
   },
   "outputs": [],
   "source": [
    "# HH CAR CONNECTIVITY\n",
    "car_ods = graph.NodesOD(car_network.g)\n",
    "\n",
    "hh_df['car_dist'], hh_df['car_node'] = spatial.distance_index_nearest_node(hhs, car_network.locs)\n",
    "work_df['car_dist'], work_df['car_node'] = spatial.distance_index_nearest_node(work, car_network.locs)\n",
    "leisure_df['car_dist'], leisure_df['car_node'] = spatial.distance_index_nearest_node(leisure, car_network.locs)\n",
    "education_df['car_dist'], education_df['car_node'] = spatial.distance_index_nearest_node(education, car_network.locs)\n",
    "health_df['car_dist'], health_df['car_node'] = spatial.distance_index_nearest_node(health, car_network.locs)\n",
    "shopping_df['car_dist'], shopping_df['car_node'] = spatial.distance_index_nearest_node(shopping, car_network.locs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T21:27:41.409035Z",
     "start_time": "2021-09-09T21:27:08.486Z"
    }
   },
   "outputs": [],
   "source": [
    "hh_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T21:27:41.417133Z",
     "start_time": "2021-09-09T21:27:08.488Z"
    }
   },
   "outputs": [],
   "source": [
    "# HH PT CONNECTIVITY\n",
    "pt_network = nx.compose(total_bus_graph, total_train_graph)\n",
    "pt_pos = {n:d['pos'] for n,d in pt_network.nodes(data=True)}\n",
    "pt_node_locs = np.array([d['pos'] for n,d in pt_network.nodes(data=True)])\n",
    "pt_ods = graph.NodesOD(pt_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T21:27:41.421377Z",
     "start_time": "2021-09-09T21:27:08.490Z"
    }
   },
   "outputs": [],
   "source": [
    "hh_df['pt_dist'], hh_df['pt_node'] = spatial.distance_index_nearest_node(hhs, pt_node_locs)\n",
    "work_df['pt_dist'], work_df['pt_node'] = spatial.distance_index_nearest_node(work, pt_node_locs)\n",
    "leisure_df['pt_dist'], leisure_df['pt_node'] = spatial.distance_index_nearest_node(leisure, pt_node_locs)\n",
    "education_df['pt_dist'], education_df['pt_node'] = spatial.distance_index_nearest_node(education, pt_node_locs)\n",
    "health_df['pt_dist'], health_df['pt_node'] = spatial.distance_index_nearest_node(health, pt_node_locs)\n",
    "shopping_df['pt_dist'], shopping_df['pt_node'] = spatial.distance_index_nearest_node(shopping, pt_node_locs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T21:27:41.431032Z",
     "start_time": "2021-09-09T21:27:08.492Z"
    }
   },
   "outputs": [],
   "source": [
    "hh_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T21:27:41.434612Z",
     "start_time": "2021-09-09T21:27:08.494Z"
    }
   },
   "outputs": [],
   "source": [
    "car_time = np.zeros((len(person_df)))\n",
    "pt_time = np.zeros((len(person_df)))\n",
    "cycle_time = np.zeros((len(person_df)))\n",
    "walk_time = np.zeros((len(person_df)))\n",
    "mode_choice = np.zeros((len(person_df)))\n",
    "journey_time = np.zeros((len(person_df)))\n",
    "\n",
    "for i, (hh_index, main_act, main_id, income_mm, age_mm, adult, children, cars) in enumerate(\n",
    "    zip(\n",
    "        person_df.hh_index,\n",
    "        person_df.main_activity,\n",
    "        person_df.main_activity_id,\n",
    "        minmax(person_df.hh_income),\n",
    "        minmax(person_df.age),\n",
    "        person_df.adult,\n",
    "        person_df.hh_children,\n",
    "        person_df.hh_cars,\n",
    "              )):\n",
    "    \n",
    "    if main_act == 0:  # home\n",
    "        mode_choice[i] = -1\n",
    "        continue\n",
    "        \n",
    "    main_id = int(main_id)\n",
    "    hh_index = int(hh_index)\n",
    "    \n",
    "    hh_loc = hhs.locs[hh_index]\n",
    "    \n",
    "    hh_car_node_dist, hh_car_node = hh_df.car_dist[hh_index], hh_df.car_node[hh_index]\n",
    "    hh_car_node_time = 1.4 * 3600 * hh_car_node_dist / 25\n",
    "    \n",
    "    hh_pt_node_dist, hh_pt_node = hh_df.pt_dist[hh_index], hh_df.pt_node[hh_index]\n",
    "    hh_pt_node_time = 3600 * hh_car_node_dist / 5\n",
    "    \n",
    "    times = {}\n",
    "    options = {}\n",
    "        \n",
    "    if main_act == 1:  # work\n",
    "        \n",
    "        facility_loc = work.locs[main_id]\n",
    "        facility_df = work_df\n",
    "        \n",
    "    if main_act == 2:  # education\n",
    "        \n",
    "        facility_loc = education.locs[main_id]\n",
    "        facility_df = education_df\n",
    "        \n",
    "    if main_act == 3:  # shopping\n",
    "        \n",
    "        facility_loc = shopping.locs[main_id]\n",
    "        facility_df = shopping_df\n",
    "        \n",
    "    if main_act == 4:  # leisure\n",
    "        \n",
    "        facility_loc = leisure.locs[main_id]\n",
    "        facility_df = leisure_df\n",
    "        \n",
    "    if main_act == 5:  # health\n",
    "        \n",
    "        facility_loc = health.locs[main_id]\n",
    "        facility_df = health_df\n",
    "     \n",
    "    # choice\n",
    "    eucl_distance = ((hh_loc - facility_loc)**2).sum()**.5\n",
    "    manh_distance = np.abs(hh_loc - facility_loc).sum()\n",
    "    \n",
    "    # car\n",
    "    facility_car_node_dist, facility_car_node = facility_df.car_dist[main_id], facility_df.car_node[main_id]\n",
    "    car_network_travel = car_ods.get(hh_car_node, facility_car_node)\n",
    "    if car_network_travel != -1:\n",
    "        facility_car_node_time = 1.4 * 3600 * facility_car_node_dist / 25\n",
    "        car_journey_time = hh_car_node_time + facility_car_node_time + car_network_travel + 300\n",
    "        if car_journey_time > 300:\n",
    "            car_time[i] = car_journey_time\n",
    "            times[0] = car_journey_time\n",
    "\n",
    "            if not cars:\n",
    "                options[0] = car_journey_time * 3\n",
    "            else:\n",
    "                options[0] = car_journey_time * (1.1 - cars / 10) * (1 - children / 10)\n",
    "    \n",
    "    # pt\n",
    "    facility_pt_node_dist, facility_pt_node = facility_df.pt_dist[main_id], facility_df.pt_node[main_id]\n",
    "    pt_network_travel = pt_ods.get(hh_pt_node, facility_pt_node)\n",
    "    if pt_network_travel != -1:\n",
    "        facility_pt_node_time = 3600 * facility_pt_node_dist / 5\n",
    "        pt_journey_time = hh_pt_node_time + facility_pt_node_time + pt_network_travel + 120\n",
    "        if pt_journey_time > 300:\n",
    "            pt_time[i] = pt_journey_time\n",
    "            times[1] = pt_journey_time\n",
    "\n",
    "            options[1] = pt_journey_time * (1 + age_mm / 100) * (1 + income_mm / 10)\n",
    "    \n",
    "    # cycle\n",
    "    cycle_journey_time = 360 * manh_distance / 15 + 120\n",
    "    if (cycle_journey_time < 3600) and (cycle_journey_time > 120):\n",
    "        cycle_time[i] = cycle_journey_time\n",
    "        times[2] = cycle_journey_time\n",
    "        \n",
    "        if main_act == 3:\n",
    "            options[2] = cycle_journey_time * 3\n",
    "        else:\n",
    "            options[2] = cycle_journey_time * (1 + age_mm / 10) * (1 + income_mm / 10)\n",
    "\n",
    "    # walk\n",
    "    walk_journey_time = 360 * eucl_distance / 5\n",
    "    if walk_journey_time < 3600:\n",
    "        walk_time[i] = walk_journey_time\n",
    "        times[3] = walk_journey_time\n",
    "        options[3] = walk_journey_time\n",
    "    \n",
    "    weights = np.array(list(options.values()))\n",
    "    weights = weights / weights.sum()\n",
    "    mode = np.random.choice(list(options), p=weights)\n",
    "    time = times[mode]\n",
    "    \n",
    "    mode_choice[i] = mode\n",
    "    journey_time[i] = time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T21:27:41.437293Z",
     "start_time": "2021-09-09T21:27:08.497Z"
    }
   },
   "outputs": [],
   "source": [
    "person_df['mode'] = mode_choice\n",
    "person_hidden_df['journey_time'] = journey_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T21:27:41.440451Z",
     "start_time": "2021-09-09T21:27:08.499Z"
    }
   },
   "outputs": [],
   "source": [
    "header = {\n",
    "    'hh_in_work': {\n",
    "        0: 'noone',\n",
    "        1: 'yes',\n",
    "    },\n",
    "    'adult': {\n",
    "        0: 'under16',\n",
    "        1: '16+',\n",
    "    },\n",
    "    'gender': {\n",
    "        0: 'male',\n",
    "        1: 'female',\n",
    "        2: 'other',\n",
    "    },\n",
    "    'employment': {\n",
    "        0: 'retired',\n",
    "        1: 'unemployed',\n",
    "        2: 'education',\n",
    "        3: 'employment',\n",
    "    },\n",
    "    'occupation': {\n",
    "        0: 'none',\n",
    "        1: 'unskilled',\n",
    "        2: 'skilled',\n",
    "        3: 'manager',\n",
    "    },\n",
    "    'main_activity': {\n",
    "        0: 'None',\n",
    "        1: 'work',\n",
    "        2: 'education',\n",
    "        3: 'shopping',\n",
    "        4: 'leisure',\n",
    "        5: 'health',\n",
    "    },\n",
    "    'mode': {\n",
    "        0: 'car',\n",
    "        1: 'PT',\n",
    "        2: 'cycle',\n",
    "        3: 'walk',\n",
    "    },\n",
    "    'hh_income_bin': {\n",
    "        0: 'low',\n",
    "        1: 'mid',\n",
    "        2: 'mid-high',\n",
    "        3: 'high',\n",
    "    },\n",
    "    'age_bin': {\n",
    "        0: '-4',\n",
    "        4: '4-13',\n",
    "        13: '13-16',\n",
    "        16: '16-21',\n",
    "        21: '21-31',\n",
    "        31: '31-41',\n",
    "        41: '41-51',\n",
    "        51: '51-61',\n",
    "        61: '61-71',\n",
    "        71: '71-81',\n",
    "        81: '81+',\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T21:27:41.445017Z",
     "start_time": "2021-09-09T21:27:08.504Z"
    }
   },
   "outputs": [],
   "source": [
    "# import json\n",
    "# with open(os.path.join(city_dir, 'header.json'), 'w') as f:\n",
    "#     json.dump(header, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T21:27:41.447769Z",
     "start_time": "2021-09-09T21:27:08.509Z"
    }
   },
   "outputs": [],
   "source": [
    "person_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T21:27:41.450595Z",
     "start_time": "2021-09-09T21:27:08.515Z"
    }
   },
   "outputs": [],
   "source": [
    "# bin the continuous variables (income and age)\n",
    "d = person_df.hh_income.describe()\n",
    "bins = [0, d['25%'], d['50%'], d['75%'], d['max']]\n",
    "labels = [0,1,2,3]\n",
    "person_df['hh_income_bin'] = pd.cut(person_df.hh_income, bins=bins, labels=labels)\n",
    "\n",
    "bins = [-1, 4, 13, 16, 21, 31, 41, 51, 61, 71, 81, 120]\n",
    "labels = ['0-4', '4-13', '13-16','16-21', '21-31', '31-41', '41-51', '51-61', '61-71', '71-81', '81+']\n",
    "# labels = [0, 4, 13, 16, 21, 31, 41, 51, 61, 71, 81]\n",
    "person_df['age_bin'] = pd.cut(person_df.age, bins=bins, labels=labels)\n",
    "\n",
    "person_df.hh_in_work = person_df.hh_in_work.map(header[\"hh_in_work\"])\n",
    "person_df.adult = person_df.adult.map(header[\"adult\"])\n",
    "person_df.gender = person_df.gender.map(header[\"gender\"])\n",
    "person_df.employment = person_df.employment.map(header[\"employment\"])\n",
    "person_df.occupation = person_df.occupation.map(header[\"occupation\"])\n",
    "person_df.main_activity = person_df.main_activity.map(header[\"main_activity\"])\n",
    "person_df[\"mode\"] = person_df[\"mode\"].map(header[\"mode\"])\n",
    "person_df.hh_income_bin = person_df.hh_income_bin.map(header[\"hh_income_bin\"])\n",
    "\n",
    "person_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Commuter Survey Output\n",
    "\n",
    "We extract tours for work and education activities and create an zone based origin - destination freq table.\n",
    "\n",
    "Note that we could further break-down by activity type and or mode choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T21:27:41.453083Z",
     "start_time": "2021-09-09T21:27:08.517Z"
    }
   },
   "outputs": [],
   "source": [
    "activities = [\"work\", \"education\"] # work & education\n",
    "commuter_df = person_df.hh_index.loc[person_df.main_activity.isin(activities)]\n",
    "commuter_freq_df = commuter_df.groupby([person_df.zone_id, person_df.main_facility_zone]).count()\n",
    "commuter_freq_df.name = 'freq'\n",
    "commuter_freq_df.to_csv(os.path.join(city_dir, 'zone_commuter_freq_table.csv'), header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T21:27:41.458224Z",
     "start_time": "2021-09-09T21:27:08.518Z"
    }
   },
   "outputs": [],
   "source": [
    "# matrix version\n",
    "commuter_freq_df.unstack().to_csv(os.path.join(city_dir, 'zone_commuter_freq_matrix.csv'), header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T21:27:41.465223Z",
     "start_time": "2021-09-09T21:27:08.520Z"
    }
   },
   "outputs": [],
   "source": [
    "person_df.to_csv(os.path.join(city_dir, 'population_survey.csv'), header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T21:27:41.467670Z",
     "start_time": "2021-09-09T21:27:08.523Z"
    }
   },
   "outputs": [],
   "source": [
    "person_df[\"mode\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9a55370b5416f60967d4532f4c3c966dd70cd0de3ce01b06e2ca05408dd0646e"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "358.4px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
